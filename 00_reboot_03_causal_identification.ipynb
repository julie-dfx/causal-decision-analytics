{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRrCDFiiZ6m0RyzXw8DtDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julie-dfx/causal-decision-analytics/blob/main/00_reboot_03_causal_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Causal identification: when effects are learnable\n",
        "\n",
        "This notebook explores the distinction between estimation and identification. Through simulations, it demonstrates cases where causal effects can be recovered by adjustment and cases where they are fundamentally not identifiable from the data\n",
        "\n",
        "*Topics: identification, selection bias, IV intuition*\n"
      ],
      "metadata": {
        "id": "jchTGsClFJuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "\n",
        " - this notebook shows that causal effects are identifiable only when the data and assumptions allow isolation of variation in the treatment independant of confounders.\n",
        " - Increasing sample size improves precision but does not resolve identification failure caused by unobserved confounding\n",
        "\n",
        " - Selection bias can arise from conditioning on post-treatment variables or restricting the samle based on outcomes that are influenced by the treatment\n",
        " Data filtering decisions can introduce bias even when regression models are otherwise correctly specified\n",
        "\n",
        " - Instrumental variables allow identification of causla effects in the presence of unobserved confounders by exploiting exogenous variation in the treatment"
      ],
      "metadata": {
        "id": "nL8dITM1Fr4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations\n",
        "\n",
        " - The examples assume simple data-genrating processes and focus on unobserved confounding as the primary source of non-identification. Other sources of non-identification, such as simultaneity or measurement error, are not yet explored\n",
        "\n",
        " - Selection mechanims are simulated explicitely; in real datasets, selection is often implicit and harder to diagnose\n",
        "\n",
        " - Instrument validity is assumed by construction. in real-world applications, the independance and exclusion assumptions are difficult to verify"
      ],
      "metadata": {
        "id": "glPKgMjWF9zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "Z9S6KEXkAyFJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backdoor criterion\n"
      ],
      "metadata": {
        "id": "_0l_rG2gwHYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#simulate a confounded world\n",
        "np.random.seed(1)\n",
        "n = 500\n",
        "\n",
        "#Confounder:\n",
        "Z = np.random.normal(0, 1, n) # --> affects both X and Y\n",
        "\n",
        "#Treatment\n",
        "X = 1.5 * Z + np.random.normal(0, 1, n)\n",
        "\n",
        "#Outcome\n",
        "Y = 2.0 * X + 3.0 * Z + np.random.normal(0, 1, n)\n",
        "\n",
        "# The backdoor path is open X <-- Z --> Y\n",
        "# True causal effect of X on Y = 2.0"
      ],
      "metadata": {
        "id": "LjonytiIwM11"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #1: no adjustment\n",
        "X1 = sm.add_constant(X)\n",
        "res1 = sm.OLS(Y, X1).fit()\n",
        "res1.params\n",
        "\n",
        "#result is far from 2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ynpRmvxj-x",
        "outputId": "c76f1a9c-77a9-4e5e-bcbe-c85eeab7c9ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09138593, 3.40609307])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #2: correct adjustment\n",
        "X2 = sm.add_constant(np.column_stack([X, Z]))\n",
        "res2 = sm.OLS(Y, X2).fit()\n",
        "res2.params\n",
        "\n",
        "#result: coefficient is close to 2; backdoor criterion in action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN6j99hax-Xk",
        "outputId": "f7177276-0f0e-4f34-fa23-7d3104e82d49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.07616095, 2.0236437 , 2.98435111])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression 3: bad adjustment (collider)\n",
        "C = X + Y + np.random.normal(0, 1, n)\n",
        "\n",
        "X3 = sm.add_constant(np.column_stack([X, C]))\n",
        "res3 = sm.OLS(Y, X3).fit()\n",
        "res3.params\n",
        "\n",
        "#result: X3 is wrong again (0.01); we introduced a bias by adjusting the wrong variable (collider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED1lvEVQyitO",
        "outputId": "6d5f7b52-a7ba-4211-942d-01a4321cc225"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04059645, 0.01346148, 0.76665627])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Empirical demonstration of the backdoor criterion\n",
        " When the confounder Z is omitted, the regression coefficient on X is biased.\n",
        " Conditioning on Z blocks the backdoor path and recovers the true causal effect.\n",
        " Conditioning on a collider re-opens a non-causal path and introduces bias, even though model fit may improve\n",
        "\n"
      ],
      "metadata": {
        "id": "um9O3-Z4zjCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Dive\n",
        "\n",
        "If we rerun for n in [100, 1000, 10000], we see that Bias persists and becomes more certain with more dta when identification is wrong\n",
        "\n",
        "If we rerun fo increased noise vs signal Y = 2.0 * X + 3.0 * Z + np.random.normal(0, 5, n), we observe that variance increases, confidence intervals widen, but bias behaviour is unchanged. Variance is about uncertainty, bias is about structure"
      ],
      "metadata": {
        "id": "nDsheGX85t1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a richer graph in code\n",
        "W = np.random.normal(0, 1, n)\n",
        "Z2 = 0.5 * Z + np.random.normal(0, 1, n)\n",
        "\n",
        "Y = 2.0 * X + 3.0 * Z + np.random.normal(0, 1, n)"
      ],
      "metadata": {
        "id": "PqmKFQwV61-D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #1: control for X only\n",
        "X1 = sm.add_constant(X)\n",
        "res1 = sm.OLS(Y, X1).fit()\n",
        "print(res1.summary())\n",
        "\n",
        "#result is far from 2.0 (3.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzKAgM297TUh",
        "outputId": "55364a68-c21d-40f0-8902-53b74e1bebac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.915\n",
            "Model:                            OLS   Adj. R-squared:                  0.915\n",
            "Method:                 Least Squares   F-statistic:                     5351.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):          1.48e-268\n",
            "Time:                        10:13:50   Log-Likelihood:                -1025.3\n",
            "No. Observations:                 500   AIC:                             2055.\n",
            "Df Residuals:                     498   BIC:                             2063.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0460      0.084      0.545      0.586      -0.120       0.212\n",
            "x1             3.4412      0.047     73.154      0.000       3.349       3.534\n",
            "==============================================================================\n",
            "Omnibus:                        1.863   Durbin-Watson:                   2.127\n",
            "Prob(Omnibus):                  0.394   Jarque-Bera (JB):                1.750\n",
            "Skew:                          -0.062   Prob(JB):                        0.417\n",
            "Kurtosis:                       2.738   Cond. No.                         1.80\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #2: control for X + W\n",
        "X2 = sm.add_constant(np.column_stack([X, W]))\n",
        "res2 = sm.OLS(Y, X2).fit()\n",
        "print(res2.summary())\n",
        "\n",
        "#result: controlling for sth that is not on the path (W) doesnt change the coeff on X, and is still wrong"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO9vJtmK-Fum",
        "outputId": "e8a650aa-4326-45db-ea73-e40597c907a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.915\n",
            "Model:                            OLS   Adj. R-squared:                  0.915\n",
            "Method:                 Least Squares   F-statistic:                     2676.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):          8.42e-267\n",
            "Time:                        10:13:50   Log-Likelihood:                -1024.8\n",
            "No. Observations:                 500   AIC:                             2056.\n",
            "Df Residuals:                     497   BIC:                             2068.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0470      0.084      0.557      0.578      -0.119       0.213\n",
            "x1             3.4420      0.047     73.156      0.000       3.350       3.534\n",
            "x2             0.0828      0.085      0.979      0.328      -0.083       0.249\n",
            "==============================================================================\n",
            "Omnibus:                        1.811   Durbin-Watson:                   2.129\n",
            "Prob(Omnibus):                  0.404   Jarque-Bera (JB):                1.723\n",
            "Skew:                          -0.066   Prob(JB):                        0.423\n",
            "Kurtosis:                       2.745   Cond. No.                         1.81\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #2: control for X + Z2 (Z2 is a descendant of Z, the confounder, but is not on the causal path to Y)\n",
        "X2 = sm.add_constant(np.column_stack([X, Z2]))\n",
        "res2 = sm.OLS(Y, X2).fit()\n",
        "print(res2.summary())\n",
        "\n",
        "#result: controlling for sth that is not on the path (Z2), even if a descendant of the confounder doesnt change the coeff on X, and is still wrong"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnuaM1E9-_29",
        "outputId": "f1385dfe-d62f-4777-a981-81485974a692"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.922\n",
            "Model:                            OLS   Adj. R-squared:                  0.922\n",
            "Method:                 Least Squares   F-statistic:                     2953.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):          1.49e-276\n",
            "Time:                        10:13:50   Log-Likelihood:                -1002.2\n",
            "No. Observations:                 500   AIC:                             2010.\n",
            "Df Residuals:                     497   BIC:                             2023.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0614      0.081      0.761      0.447      -0.097       0.220\n",
            "x1             3.3144      0.049     68.278      0.000       3.219       3.410\n",
            "x2             0.5496      0.079      6.932      0.000       0.394       0.705\n",
            "==============================================================================\n",
            "Omnibus:                        1.408   Durbin-Watson:                   2.082\n",
            "Prob(Omnibus):                  0.495   Jarque-Bera (JB):                1.472\n",
            "Skew:                          -0.091   Prob(JB):                        0.479\n",
            "Kurtosis:                       2.806   Cond. No.                         1.92\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression #2: control for X + Z + W (controlling both for the confounder and for sth that is not on the causal path)\n",
        "X2 = sm.add_constant(np.column_stack([X, Z, W]))\n",
        "res2 = sm.OLS(Y, X2).fit()\n",
        "print(res2.summary())\n",
        "\n",
        "#result: controlling for the confounder + for sth random gives correct results. It's just useless to control for W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xlw3ooo_WNs",
        "outputId": "db3fede5-25c8-4499-bef3-587cbe3f4f6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.975\n",
            "Model:                            OLS   Adj. R-squared:                  0.975\n",
            "Method:                 Least Squares   F-statistic:                     6450.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:13:50   Log-Likelihood:                -718.87\n",
            "No. Observations:                 500   AIC:                             1446.\n",
            "Df Residuals:                     496   BIC:                             1463.\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0314      0.046      0.684      0.494      -0.059       0.121\n",
            "x1             2.0787      0.047     44.177      0.000       1.986       2.171\n",
            "x2             2.9420      0.085     34.501      0.000       2.774       3.109\n",
            "x3             0.0298      0.046      0.650      0.516      -0.060       0.120\n",
            "==============================================================================\n",
            "Omnibus:                        1.930   Durbin-Watson:                   1.902\n",
            "Prob(Omnibus):                  0.381   Jarque-Bera (JB):                2.003\n",
            "Skew:                           0.127   Prob(JB):                        0.367\n",
            "Kurtosis:                       2.822   Cond. No.                         4.12\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REAL EXAMPLE\n",
        "\n",
        "- X = compensation issued\n",
        "- Y = 28-day retention\n",
        "- Z = order issue severity\n",
        "- C = basket value\n",
        "\n",
        "\n",
        "\n",
        "1.   severity --> compensation --> retention\n",
        "2.   severity --> retention\n",
        "3.   compensation --> basket value <-- retention\n",
        "\n",
        "\n",
        "The backdoor path is open: severity is the confounder\n",
        "Basket Value is influenced by both X and Y, it's the collider and should not be controlled for\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DO4uil2d_6rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identification vs Estimation"
      ],
      "metadata": {
        "id": "Hl9jlv3l6L5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can this causal effect be learned from the data at all, even with infinite data?\n"
      ],
      "metadata": {
        "id": "WY7YX2eMICak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## We simulate 2 worlds, one where regression is biased but fixable by adjustment, one where it's not\n",
        "\n",
        "## World A\n",
        "np.random.seed(1)\n",
        "n = 1000\n",
        "\n",
        "Z = np.random.normal(0, 1, n)\n",
        "X = Z + np.random.normal(0, 1, n)\n",
        "Y = 2 * X + 3 *  Z + np.random.normal(0, 1, n)"
      ],
      "metadata": {
        "id": "6F9-QZKo_3IY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run 2 regressions\n",
        "\n",
        "#unadjusted\n",
        "res_unadj = sm.OLS(Y, sm.add_constant(X)).fit()\n",
        "\n",
        "#adjusted\n",
        "res_adj = sm.OLS(Y, sm.add_constant(np.column_stack([X, Z]))).fit()\n",
        "\n",
        "print(res_unadj.summary())\n",
        "print(res_adj.summary())\n",
        "\n",
        "# results: adjusted ~2, unadj <>2 ; the effect is identifiable because a valid adjustment set exists"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GSnq6Xy7Amb",
        "outputId": "be063c13-f080-474b-9d34-571e08379b90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.817\n",
            "Model:                            OLS   Adj. R-squared:                  0.817\n",
            "Method:                 Least Squares   F-statistic:                     4453.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:13:50   Log-Likelihood:                -2255.0\n",
            "No. Observations:                1000   AIC:                             4514.\n",
            "Df Residuals:                     998   BIC:                             4524.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0024      0.073      0.032      0.974      -0.141       0.146\n",
            "x1             3.3896      0.051     66.733      0.000       3.290       3.489\n",
            "==============================================================================\n",
            "Omnibus:                        1.510   Durbin-Watson:                   2.087\n",
            "Prob(Omnibus):                  0.470   Jarque-Bera (JB):                1.527\n",
            "Skew:                          -0.051   Prob(JB):                        0.466\n",
            "Kurtosis:                       2.838   Cond. No.                         1.44\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.968\n",
            "Model:                            OLS   Adj. R-squared:                  0.968\n",
            "Method:                 Least Squares   F-statistic:                 1.491e+04\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:13:50   Log-Likelihood:                -1388.4\n",
            "No. Observations:                1000   AIC:                             2783.\n",
            "Df Residuals:                     997   BIC:                             2797.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0194      0.031     -0.632      0.527      -0.080       0.041\n",
            "x1             1.9708      0.030     66.070      0.000       1.912       2.029\n",
            "x2             2.9797      0.044     68.153      0.000       2.894       3.065\n",
            "==============================================================================\n",
            "Omnibus:                        0.790   Durbin-Watson:                   2.063\n",
            "Prob(Omnibus):                  0.674   Jarque-Bera (JB):                0.806\n",
            "Skew:                           0.068   Prob(JB):                        0.668\n",
            "Kurtosis:                       2.974   Cond. No.                         2.62\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# World B - not identifiable\n",
        "\n",
        "np.random.seed(1)\n",
        "# n = 10000\n",
        "U = np.random.normal(0, 1, n) # unobserved confounder\n",
        "\n",
        "X = U + np.random.normal(0, 1, n)\n",
        "Y = 2 * X + U + np.random.normal(0, 1, n)"
      ],
      "metadata": {
        "id": "o2XHMLg47oe3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = sm.OLS(Y, sm.add_constant(X)).fit()\n",
        "print(res.summary())\n",
        "\n",
        "#result: 2, 4, false. not identifiable. When increasing n, the results converge but not to 2 ==> not a variance problem, but an identification failure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT2H23f08ov6",
        "outputId": "549ede95-4cc0-4d91-9ac3-8ac01a66c841"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.897\n",
            "Model:                            OLS   Adj. R-squared:                  0.897\n",
            "Method:                 Least Squares   F-statistic:                     8665.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:13:50   Log-Likelihood:                -1592.3\n",
            "No. Observations:                1000   AIC:                             3189.\n",
            "Df Residuals:                     998   BIC:                             3198.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0123      0.038     -0.326      0.745      -0.086       0.062\n",
            "x1             2.4373      0.026     93.087      0.000       2.386       2.489\n",
            "==============================================================================\n",
            "Omnibus:                        1.287   Durbin-Watson:                   2.090\n",
            "Prob(Omnibus):                  0.525   Jarque-Bera (JB):                1.228\n",
            "Skew:                           0.085   Prob(JB):                        0.541\n",
            "Kurtosis:                       3.022   Cond. No.                         1.44\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identification vs Estimation\n",
        "\n",
        "In world A, the causal effect of X on Y is identifiable because a valid adjustment set exists. Conditioning on Z blocks all backdoor paths\n",
        "\n",
        "In world B, the causal effect is not identifiable from the observed data because the confounder is unobserved. Increasing sample size improves precision but does not remove bias"
      ],
      "metadata": {
        "id": "nUJoEJcw9Di6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selection bias and post-treatment variables\n",
        "Why \"cleaning data\" often breaks causality.\n",
        "\n",
        "This section simulates a situation where : the casual effect is identifiable in principle, but the selection decision destroys identifiability (eg: \"let's look only at delivered orders\""
      ],
      "metadata": {
        "id": "QOk6aGc5_So6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "n = 2000\n",
        "\n",
        "#Unobserved customerquality\n",
        "U = np.random.normal(0, 1, n)\n",
        "\n",
        "#treatment (compensation)\n",
        "X = U + np.random.normal(0, 1, n)\n",
        "\n",
        "#outcome (retention)\n",
        "Y = 2 * X + U + np.random.normal(0, 1, n)\n",
        "\n",
        "## U affects both treatment and outcome\n",
        "## in the full population, this is confounded but conceptually identifiable iif U were observed (it is not)"
      ],
      "metadata": {
        "id": "5ofA6TkgAdqJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce bias:\n",
        "\n",
        "#selection variable (delivered / observed)\n",
        "S = (X + Y + np.random.normal(0, 1, n)) > 0\n",
        "\n",
        "## S is affected by both X and Y, it's a Collider\n",
        "## Conditioning on S is selection bias"
      ],
      "metadata": {
        "id": "Y3lYWB-bBjTS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression on the full population\n",
        "\n",
        "res_full = sm.OLS(Y, sm.add_constant(X)).fit()\n",
        "print(res_full.summary())\n",
        "\n",
        "# this is biased because of the confounder, but that's not the topic for now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTch1HmaB4en",
        "outputId": "747e46d3-969f-4639-e09a-5bf215096d1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.892\n",
            "Model:                            OLS   Adj. R-squared:                  0.891\n",
            "Method:                 Least Squares   F-statistic:                 1.642e+04\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:13:50   Log-Likelihood:                -3242.1\n",
            "No. Observations:                2000   AIC:                             6488.\n",
            "Df Residuals:                    1998   BIC:                             6499.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0330      0.027      1.203      0.229      -0.021       0.087\n",
            "x1             2.4987      0.019    128.158      0.000       2.460       2.537\n",
            "==============================================================================\n",
            "Omnibus:                        2.268   Durbin-Watson:                   1.985\n",
            "Prob(Omnibus):                  0.322   Jarque-Bera (JB):                2.284\n",
            "Skew:                           0.034   Prob(JB):                        0.319\n",
            "Kurtosis:                       3.151   Cond. No.                         1.41\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# regression on the selected sample:\n",
        "\n",
        "X_sel = X[S]\n",
        "Y_sel = Y[S]\n",
        "\n",
        "res_sel = sm.OLS(Y_sel, sm.add_constant(X_sel)).fit()\n",
        "print(res_sel.summary())\n",
        "\n",
        "# the coefficient changes --> this is selection bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkAauyhkCUx3",
        "outputId": "d7638be5-7aaa-4726-8b87-437181d29b1e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.757\n",
            "Model:                            OLS   Adj. R-squared:                  0.757\n",
            "Method:                 Least Squares   F-statistic:                     3157.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):          2.17e-313\n",
            "Time:                        10:13:50   Log-Likelihood:                -1598.7\n",
            "No. Observations:                1014   AIC:                             3201.\n",
            "Df Residuals:                    1012   BIC:                             3211.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.5503      0.056      9.783      0.000       0.440       0.661\n",
            "x1             2.2101      0.039     56.189      0.000       2.133       2.287\n",
            "==============================================================================\n",
            "Omnibus:                        5.503   Durbin-Watson:                   2.006\n",
            "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                5.408\n",
            "Skew:                           0.176   Prob(JB):                       0.0669\n",
            "Kurtosis:                       3.064   Cond. No.                         2.91\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection bias vs post-treatment variables:\n",
        "Restricting the analysis to selected observations is conditioning on a variable that is influenced by both the treatment and the outcome. This introduces bias by opening a non-causal path between X and Y, even if the full population effect were otherwise identifiable"
      ],
      "metadata": {
        "id": "sUBBQavjC8ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instrumental Variables (IV)\n",
        "\n",
        "IV is used when the causal effect of X on Y is not identifiable by aadjustement, becasue a confounder is unobserved; but we do have a variable that creates exogenous variation in X --> we use external variation in X that is unrelated to the confounder"
      ],
      "metadata": {
        "id": "h78flLXKvzvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate a world with unobserved confounding\n",
        "\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
        "\n",
        "np.random.seed(1)\n",
        "n = 3000\n",
        "\n",
        "# unobserved confounder\n",
        "U = np.random.normal(0, 1, n)\n",
        "\n",
        "# Instrument\n",
        "Z = np.random.normal(0, 1, n)\n",
        "\n",
        "#treatment (endogenous)\n",
        "X = 2 * Z + U + np.random.normal(0, 1, n)\n",
        "\n",
        "# Outcome\n",
        "Y = 3 * X + U + np.random.normal(0, 1, n)\n",
        "\n",
        "\n",
        "# U affects both X and Y, it's the confounder\n",
        "# Z affects X but not Y directly\n",
        "# Z is independant of U --> Ideal IV world"
      ],
      "metadata": {
        "id": "rdW8LL7swKoJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regression (naive)\n",
        "res_ols = sm.OLS(Y, sm.add_constant(X)).fit()\n",
        "print(res_ols.summary())\n",
        "\n",
        "# results: coeff > 3 ; bias persists whatever n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq6toSktxMB3",
        "outputId": "5f1f9a33-2aae-4d42-dd5c-7c5bbca11234"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.970\n",
            "Model:                            OLS   Adj. R-squared:                  0.970\n",
            "Method:                 Least Squares   F-statistic:                 9.790e+04\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:20:32   Log-Likelihood:                -5169.0\n",
            "No. Observations:                3000   AIC:                         1.034e+04\n",
            "Df Residuals:                    2998   BIC:                         1.035e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0324      0.025      1.310      0.190      -0.016       0.081\n",
            "x1             3.1716      0.010    312.892      0.000       3.152       3.191\n",
            "==============================================================================\n",
            "Omnibus:                        0.931   Durbin-Watson:                   2.041\n",
            "Prob(Omnibus):                  0.628   Jarque-Bera (JB):                0.954\n",
            "Skew:                          -0.042   Prob(JB):                        0.621\n",
            "Kurtosis:                       2.979   Cond. No.                         2.44\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# endogenous regressor\n",
        "X_endog = X\n",
        "\n",
        "#exogenous regressor\n",
        "X_exog = np.ones((n, 1))\n",
        "\n",
        "# instruments = exogenous regressors + instrument Z\n",
        "Z_instr = np.column_stack([np.ones(n), Z])\n",
        "\n",
        "iv_res = IV2SLS(Y, X_exog, X_endog, Z_instr).fit()\n",
        "print(iv_res.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9JPBUFHj2SRw",
        "outputId": "78c66e41-9deb-4371-b09b-594dd2b6c7bc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "IV2SLS.__init__() takes from 3 to 4 positional arguments but 5 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2593510192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mZ_instr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0miv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIV2SLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_exog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_endog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_instr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miv_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: IV2SLS.__init__() takes from 3 to 4 positional arguments but 5 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IV2SLS code doesnt work so let's do the 2 steps manually:\n",
        "\n",
        "first_stage = sm.OLS(X, sm.add_constant(Z)).fit()\n",
        "print(first_stage.summary())\n",
        "\n",
        "# coeff on Z is large and significant, which confirms relevance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZTcOQVz3JXB",
        "outputId": "88e9aac8-708c-4c11-a0ca-1d99e5ca93b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.671\n",
            "Model:                            OLS   Adj. R-squared:                  0.671\n",
            "Method:                 Least Squares   F-statistic:                     6113.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:46:48   Log-Likelihood:                -5268.1\n",
            "No. Observations:                3000   AIC:                         1.054e+04\n",
            "Df Residuals:                    2998   BIC:                         1.055e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0150      0.026      0.585      0.559      -0.035       0.065\n",
            "x1             1.9860      0.025     78.184      0.000       1.936       2.036\n",
            "==============================================================================\n",
            "Omnibus:                        2.119   Durbin-Watson:                   2.028\n",
            "Prob(Omnibus):                  0.347   Jarque-Bera (JB):                2.077\n",
            "Skew:                           0.030   Prob(JB):                        0.354\n",
            "Kurtosis:                       2.886   Cond. No.                         1.01\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate predicted treatment\n",
        "\n",
        "X_hat = first_stage.predict(sm.add_constant(Z))\n",
        "\n",
        "# X_hat contains only the variation in X that is due to Z"
      ],
      "metadata": {
        "id": "7Kqdu7Ue3hmV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#second stage\n",
        "\n",
        "second_stage = sm.OLS(Y, sm.add_constant(X_hat)).fit()\n",
        "print(second_stage.summary())\n",
        "\n",
        "\n",
        "#results: coeff on X_hat is very close to 3 --> this is the IV estimate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IeFXJDx3vsS",
        "outputId": "eabb1e5d-505a-4a33-e710-a1b18df957d6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.587\n",
            "Model:                            OLS   Adj. R-squared:                  0.587\n",
            "Method:                 Least Squares   F-statistic:                     4256.\n",
            "Date:                Mon, 19 Jan 2026   Prob (F-statistic):               0.00\n",
            "Time:                        10:49:18   Log-Likelihood:                -9117.8\n",
            "No. Observations:                3000   AIC:                         1.824e+04\n",
            "Df Residuals:                    2998   BIC:                         1.825e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0377      0.092      0.409      0.683      -0.143       0.219\n",
            "x1             3.0109      0.046     65.241      0.000       2.920       3.101\n",
            "==============================================================================\n",
            "Omnibus:                        0.687   Durbin-Watson:                   2.026\n",
            "Prob(Omnibus):                  0.709   Jarque-Bera (JB):                0.737\n",
            "Skew:                          -0.003   Prob(JB):                        0.692\n",
            "Kurtosis:                       2.924   Cond. No.                         2.00\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation\n",
        "\n",
        "- first stage removed the confounded part of X\n",
        "- second stage used only the exogenous variation\n",
        "- as a result, bias is gone\n",
        "\n"
      ],
      "metadata": {
        "id": "CrV7nyu74Elm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instrumental variables via two-stage least squares\n",
        "\n",
        "Ordinary Least Squares (OLS) fails to recover the causal effect of X on Y due to unobserved confounding.\n",
        "\n",
        "Two-stage least squares was implemented manually by first regressing the treatment X on the instrument Z to extract exogenous variation, and then regressing the outcome Y on the predicted treatment.\n",
        "\n",
        "Under the relevance, independance and exclusion IV assumptions, this procedure recovers the true causal effect using variation in X that is unrelated to the unobserved confounder\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "TmbFPkdF4EUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "Instrumental variables are used full when confounding cannot be addressed by adjustment. An instrument provides exogenous variation in the treatment that is independant of confounders and affects the outcome only through the treatment (strongly and significantly). IV identifies a causal effect under strong assumptions that must be justified using domain knowledge rather than statistical tests"
      ],
      "metadata": {
        "id": "rrBke1O77mlq"
      }
    }
  ]
}